{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc1281b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from src.models.hmm import HiddenMarkovModel\n",
    "from src.models.decoders import ViterbiAlgorithm\n",
    "from test import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "543c8d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "observation_states = ['anxiety prone', 'not prone to anxiety']\n",
    "hidden_states = ['adopted through shelter', 'not adopted']\n",
    "\n",
    "prior_p = np.array([0.3, 0.7])\n",
    "transition_p = np.array([[0.25, 0.75],\n",
    "                         [0.45, 0.55]])\n",
    "emission_p = np.array([[0.65, 0.35],\n",
    "                      [0.15, 0.85]])\n",
    "\n",
    "obs_state_sequence = ['not prone to anxiety', 'anxiety prone', 'not prone to anxiety', 'not prone to anxiety', 'anxiety prone']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b055df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "hmm_dog_anxiety = HiddenMarkovModel(observation_states = observation_states,\n",
    "                                        hidden_states = hidden_states,\n",
    "                                        prior_probabilities = prior_p,\n",
    "                                        transition_probabilities = transition_p,\n",
    "                                        emission_probabilities = emission_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dec48bdf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dog_anxiety_viterbi = ViterbiAlgorithm(hmm_dog_anxiety)\n",
    "    \n",
    "viterbi_sequence = dog_anxiety_viterbi.best_hidden_state_sequence(obs_state_sequence)\n",
    "\n",
    "hid_state_sequence = np.array(['not adopted', 'adopted through shelter', 'adopted through shelter', 'not adopted', 'adopted through shelter'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "058a42d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.alltrue(hid_state_sequence == viterbi_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd5969ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# index annotation observation_states=[i,j]    \n",
    "observation_states = ['committed','ambivalent'] # A graduate student's dedication to their rotation lab\n",
    "    \n",
    "# index annotation hidden_states=[i,j]\n",
    "hidden_states = ['R01','R21'] # The NIH funding source of the graduate student's rotation project \n",
    "\n",
    "# PONDERING QUESTION: How would a user define/compute their own HMM instantiation inputs to decode the hidden states for their use case observations?\n",
    "use_case_one_data = np.load('./data/UserCase-Lecture.npz')\n",
    "\n",
    "# Instantiate submodule class models.HiddenMarkovModel with\n",
    "# observation and hidden states and prior, transition, and emission probabilities.\n",
    "use_case_one_hmm = HiddenMarkovModel(observation_states,\n",
    "                                    hidden_states,\n",
    "                    use_case_one_data['prior_probabilities'], # prior probabilities of hidden states in the order specified in the hidden_states list\n",
    "                    use_case_one_data['transition_probabilities'], # transition_probabilities[:,hidden_states[i]]\n",
    "                    use_case_one_data['emission_probabilities']) # emission_probabilities[hidden_states[i],:][:,observation_states[j]]\n",
    "    \n",
    "# Instantiate submodule class models.ViterbiAlgorithm using the use case one HMM \n",
    "use_case_one_viterbi = ViterbiAlgorithm(use_case_one_hmm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6aaf6e97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['R01', 'R01', 'R21', 'R21', 'R21', 'R01'], dtype='<U3')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "use_case_one_viterbi.best_hidden_state_sequence(use_case_one_data['observation_states'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0b81c4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "observation_states = ['Gold or above', 'below Gold']\n",
    "hidden_states = ['fight stick', 'gamepad']\n",
    "\n",
    "prior_p = np.array([0.55, 0.45])\n",
    "transition_p = np.array([[0.6, 0.4],\n",
    "                             [0.35, 0.65]])\n",
    "emission_p = np.array([[0.5, 0.5],\n",
    "                          [0.35, 0.65]])\n",
    "    \n",
    "obs_state_sequence = ['below Gold', 'below Gold', 'Gold or above', 'below Gold', 'Gold or above']\n",
    "hid_state_sequence = np.array(['gamepad', 'fight stick', 'fight stick', 'fight stick', 'fight stick'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2e1be6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "hmm_rank_controller = HiddenMarkovModel(observation_states = observation_states,\n",
    "                                        hidden_states = hidden_states,\n",
    "                                        prior_probabilities = prior_p,\n",
    "                                        transition_probabilities = transition_p,\n",
    "                                        emission_probabilities = emission_p)\n",
    "    \n",
    "rank_controller_viterbi = ViterbiAlgorithm(hmm_rank_controller)\n",
    "    \n",
    "viterbi_sequence = rank_controller_viterbi.best_hidden_state_sequence(obs_state_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "683587fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.alltrue(hid_state_sequence == viterbi_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bf35b3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# index annotation observation_states=[i,j]    \n",
    "observation_states = ['on-time','late'] \n",
    "\n",
    "    # index annotation hidden_states=[i,j]\n",
    "hidden_states = ['no-traffic','traffic']\n",
    "\n",
    "    # PONDERING QUESTION: How would a user define/compute their own HMM instantiation inputs to decode the hidden states for their use case observations?\n",
    "use_case_one_data = np.load('./data/UserCase-One.npz')\n",
    "\n",
    "    # Instantiate submodule class models.HiddenMarkovModel with\n",
    "    # observation and hidden states and prior, transition, and emission probabilities.\n",
    "use_case_one_hmm = HiddenMarkovModel(observation_states,\n",
    "                                     hidden_states,\n",
    "                                     use_case_one_data['prior_probabilities'], # prior probabilities of hidden states in the order specified in the hidden_states list\n",
    "                                     use_case_one_data['transition_probabilities'], # transition_probabilities[:,hidden_states[i]]\n",
    "                                     use_case_one_data['emission_probabilities']) # emission_probabilities[hidden_states[i],:][:,observation_states[j]]\n",
    "    \n",
    "    # Instantiate submodule class models.ViterbiAlgorithm using the use case one HMM \n",
    "use_case_one_viterbi = ViterbiAlgorithm(use_case_one_hmm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "56e7d5a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['no-traffic', 'no-traffic', 'traffic', 'traffic', 'traffic',\n",
       "       'no-traffic'], dtype='<U10')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "use_case_decoded_hidden_states = use_case_one_viterbi.best_hidden_state_sequence(use_case_one_data['observation_states'])\n",
    "use_case_decoded_hidden_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4ecf85c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['no-traffic', 'no-traffic', 'traffic', 'traffic', 'traffic',\n",
       "       'on-time'], dtype='<U10')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "use_case_one_data['hidden_states']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
